{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOeix9Bdfxo0issWg6zNkvL"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests"
      ],
      "metadata": {
        "id": "hSCQAAVlHPxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"Machine learning\""
      ],
      "metadata": {
        "id": "MLtq6BAik248"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "LsDBqt8w3qTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def search_wikipedia(topic):\n",
        "    search_url = f\"https://en.wikipedia.org/w/api.php?action=query&list=search&srsearch={topic}&format=json\"\n",
        "    response = requests.get(search_url)\n",
        "    search_results = response.json()\n",
        "    return search_results['query']['search']\n",
        "\n",
        "def clean_snippet(snippet):\n",
        "    soup = BeautifulSoup(snippet, \"html.parser\")\n",
        "    return soup.get_text()\n",
        "\n",
        "# Example usage\n",
        "topic = \"Machine learning\"\n",
        "search_results = search_wikipedia(topic)\n",
        "\n",
        "# Extract titles from the search results\n",
        "titles = [result['title'] for result in search_results]\n",
        "\n",
        "print(\"Related topics:\")\n",
        "for title in titles:\n",
        "    print(title)\n",
        "\n",
        "# Optional: Convert the titles to a DataFrame if needed\n",
        "df = pd.DataFrame(titles, columns=[\"Title\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLfByg8Cllug",
        "outputId": "d866d7b8-d620-4269-a55b-c8adce8cdf82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Related topics:\n",
            "Machine learning\n",
            "Quantum machine learning\n",
            "Artificial intelligence in industry\n",
            "Machine learning control\n",
            "Neural network (machine learning)\n",
            "Transformer (deep learning architecture)\n",
            "Attention (machine learning)\n",
            "Machine learning in bioinformatics\n",
            "Boosting (machine learning)\n",
            "Adversarial machine learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def get_wikipedia_extract(title, length=\"short\"):\n",
        "    # Define the endpoint\n",
        "    endpoint = \"https://en.wikipedia.org/w/api.php\"\n",
        "\n",
        "    # Set the extract length parameters\n",
        "    if length == \"short\":\n",
        "        exchars = 500  # Limit to approximately one paragraph\n",
        "        params = {\n",
        "            \"action\": \"query\",\n",
        "            \"format\": \"json\",\n",
        "            \"titles\": title,\n",
        "            \"prop\": \"extracts\",\n",
        "            \"exchars\": exchars,\n",
        "            \"explaintext\": True\n",
        "        }\n",
        "    elif length == \"medium\":\n",
        "        exsentences = 5  # Limit to approximately two paragraphs\n",
        "        params = {\n",
        "            \"action\": \"query\",\n",
        "            \"format\": \"json\",\n",
        "            \"titles\": title,\n",
        "            \"prop\": \"extracts\",\n",
        "            \"exsentences\": exsentences,\n",
        "            \"explaintext\": True\n",
        "        }\n",
        "    else:\n",
        "        params = {\n",
        "            \"action\": \"query\",\n",
        "            \"format\": \"json\",\n",
        "            \"titles\": title,\n",
        "            \"prop\": \"extracts\",\n",
        "            \"exintro\": True,\n",
        "            \"explaintext\": True\n",
        "        }\n",
        "\n",
        "    # Make the request to the Wikipedia API\n",
        "    response = requests.get(endpoint, params=params)\n",
        "    data = response.json()\n",
        "\n",
        "    # Extract the page information\n",
        "    pages = data['query']['pages']\n",
        "    page = next(iter(pages.values()))  # Get the first (and only) page\n",
        "\n",
        "    # Extract the extract text\n",
        "    extract = page.get(\"extract\", \"No extract found.\")\n",
        "\n",
        "    return extract\n",
        "\n",
        "# Example usage\n",
        "title = \"Machine learning\"\n",
        "length = \"full\"  # Options: \"short\", \"medium\", \"full\"\n",
        "extract = get_wikipedia_extract(title, length)\n",
        "print(extract)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zsha-gbq31_V",
        "outputId": "5f4a7aa0-7ca7-4bbc-d7ba-32126008d4db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalize to unseen data, and thus perform tasks without explicit instructions. Recently, artificial neural networks have been able to surpass many previous approaches in performance.\n",
            "ML finds application in many fields, including natural language processing, computer vision, speech recognition, email filtering, agriculture, and medicine. When applied to business problems, it is known under the name predictive analytics. Although not all machine learning is statistically based, computational statistics is an important source of the field's methods.\n",
            "The mathematical foundations of ML are provided by mathematical optimization (mathematical programming) methods. Data mining is a related (parallel) field of study, focusing on exploratory data analysis (EDA) through unsupervised learning. \n",
            "From a theoretical viewpoint, probably approximately correct (PAC) learning provides a framework for describing machine learning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OpenAI"
      ],
      "metadata": {
        "id": "7qBEEb2oBRdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=''\n",
        ")"
      ],
      "metadata": {
        "id": "iz2qiUgMurQu"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "    model='gpt-3.5-turbo',\n",
        "    messages=[\n",
        "        {'role':'system','content':'you are a good teacher who sets a good exam papers'},\n",
        "        {'role': 'user','content':'create 50 multiple choice questions of topic machine learning with easy complexity, and mention all the answers at last.'}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYOFTftuuwwf",
        "outputId": "dbbdf421-af87-4942-f1d5-4503f62fa79f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content=\"**Machine Learning Multiple Choice Questions**\\n\\n1. What is machine learning?\\n    A. A type of programming language\\n    B. A branch of artificial intelligence\\n    C. A type of software application\\n    D. A physical machine that learns\\n\\n2. Which of the following is not a type of machine learning?\\n    A. Supervised Learning\\n    B. Unsupervised Learning\\n    C. Reinforcement Learning\\n    D. Manual Learning\\n\\n3. What is the goal of supervised learning?\\n    A. To teach the model without any labels\\n    B. To classify input data into predefined categories\\n    C. To improve the performance of the model over time\\n    D. To assess the model's decision-making abilities\\n\\n4. Which algorithm is commonly used for classification tasks in machine learning?\\n    A. K-Means Clustering\\n    B. Linear Regression\\n    C. Support Vector Machines\\n    D. Principal Component Analysis\\n\\n5. Which evaluation metric is commonly used for regression tasks?\\n    A. Accuracy\\n    B. Precision\\n    C. F1 Score\\n    D. Mean Squared Error\\n\\n6. What is overfitting in machine learning?\\n    A. When the model performs well on training data but poorly on unseen data\\n    B. When the model performs poorly on training data and unseen data\\n    C. When the model converges too quickly during training\\n    D. When the model is unable to learn from the training data\\n\\n7. Which of the following is an example of unsupervised learning?\\n    A. Image Classification\\n    B. Clustering\\n    C. Sentiment Analysis\\n    D. Regression Analysis\\n\\n8. What is the purpose of feature scaling in machine learning?\\n    A. To increase the size of the dataset\\n    B. To standardize the range of features in the dataset\\n    C. To add new features to the dataset\\n    D. To remove irrelevant features from the dataset\\n\\n9. Which algorithm is used for anomaly detection in machine learning?\\n    A. Decision Trees\\n    B. Random Forest\\n    C. K-Means Clustering\\n    D. Isolation Forest\\n\\n10. What is the role of hyperparameters in machine learning algorithms?\\n    A. They are the parameters learned by the model during training\\n    B. They are constants set before the learning process begins\\n    C. They are the input features to the model\\n    D. They are used to evaluate the performance of the model\\n\\n**Answers:**\\n1. B\\n2. D\\n3. B\\n4. C\\n5. D\\n6. A\\n7. B\\n8. B\\n9. D\\n10. B\\n\\n(Note: Please note that these questions are designed for educational purposes and do not cover all aspects of machine learning.)\", role='assistant', function_call=None, tool_calls=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U6pA_ItTuw5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NQ_3LmcKuw-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Manual Question generator"
      ],
      "metadata": {
        "id": "k0Suyw1zuxCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def convert_to_question(sentence):\n",
        "    # List of auxiliary verbs to identify questions\n",
        "    question_words = [\"is\", \"are\", \"am\", \"was\", \"were\", \"can\", \"could\", \"shall\", \"should\", \"will\", \"would\", \"do\", \"does\", \"did\", \"have\", \"has\", \"had\", \"may\", \"might\", \"must\"]\n",
        "\n",
        "    # Split the sentence into words\n",
        "    words = sentence.split()\n",
        "\n",
        "    # Regex to identify verbs\n",
        "    verb_regex = re.compile(r\"\\bis\\b|\\bare\\b|\\bam\\b|\\bwas\\b|\\bwere\\b|\\bcan\\b|\\bcould\\b|\\bshall\\b|\\bshould\\b|\\bwill\\b|\\bwould\\b|\\bdo\\b|\\bdoes\\b|\\bdid\\b|\\bhave\\b|\\bhas\\b|\\bhad\\b|\\bmay\\b|\\bmight\\b|\\bmust\\b\")\n",
        "\n",
        "    # Find the first auxiliary verb in the sentence\n",
        "    for i, word in enumerate(words):\n",
        "        if verb_regex.match(word.lower()):\n",
        "            # Ensure we handle 'have' correctly\n",
        "            if word.lower() == \"have\" and i != 0:\n",
        "                question_sentence = \"Do \" + \" \".join(words[:i] + [words[i]] + words[i+1:]) + \"?\"\n",
        "            else:\n",
        "                # Move the auxiliary verb to the front\n",
        "                question_sentence = word + \" \" + \" \".join(words[:i] + words[i+1:]) + \"?\"\n",
        "            return question_sentence.capitalize()\n",
        "\n",
        "    # Handle sentences without auxiliary verbs by adding 'do'\n",
        "    if len(words) > 1:\n",
        "        return \"Do \" + sentence + \"?\"\n",
        "    else:\n",
        "        return sentence + \"?\"\n",
        "\n",
        "def paragraph_to_questions(paragraph):\n",
        "    # Split the paragraph into sentences\n",
        "    sentences = re.split(r'(?<=[.!?]) +', paragraph)\n",
        "    questions = [convert_to_question(sentence.strip()) for sentence in sentences if sentence.strip()]\n",
        "    return questions\n",
        "\n",
        "# Example input paragraph\n",
        "paragraph = \"\"\"\n",
        "This is not true\n",
        "\"\"\"\n",
        "\n",
        "# Generate questions\n",
        "questions = paragraph_to_questions(paragraph)\n",
        "for question in questions:\n",
        "    print(question)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_VYImzx2Id2",
        "outputId": "745a2d75-53b8-4d66-e0cc-6ce0a084b76a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is this not true?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Huggin-Face model for generating question"
      ],
      "metadata": {
        "id": "DKypuhga5Osf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load the question generation pipeline\n",
        "question_generator = pipeline(\"text2text-generation\", model=\"valhalla/t5-base-qg-hl\")\n"
      ],
      "metadata": {
        "id": "p1jhBiE25m6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_question(statement):\n",
        "    # Add highlighting for the answer (this is required for the model to understand the context)\n",
        "    input_text = \"generate question: \" + statement\n",
        "    result = question_generator(input_text)\n",
        "    return result[0]['generated_text']\n",
        "\n",
        "\n",
        "# Convert a paragraph to questions for each line\n",
        "def paragraph_to_questions(paragraph):\n",
        "    lines = paragraph.split('\\n')\n",
        "    questions = [convert_to_question(line.strip()) for line in lines if line.strip()]\n",
        "    return questions"
      ],
      "metadata": {
        "id": "bL62zvSd5rok"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example input paragraph\n",
        "paragraph = \"\"\"\n",
        "Trip list includes names of Sejal and his boy-friend\n",
        "\"\"\"\n",
        "\n",
        "# Generate questions\n",
        "questions = paragraph_to_questions(paragraph)\n",
        "for question in questions:\n",
        "    print(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3O33dGB5-My",
        "outputId": "4a1f549a-4e39-4fad-9990-06d43a83332f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is Sejal's name on the trip list?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Gs2x5hX8-yp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}